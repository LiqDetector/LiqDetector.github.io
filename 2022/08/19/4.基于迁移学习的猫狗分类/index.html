


<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>  迁移学习猫狗图像分类 |    Fan&#39;s Notebook.</title>
  <meta name="description" content="Fan">
  <!-- 标签页图标 -->
  
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
  

  <!-- 图标库 -->
  <link href="https://cdn.jsdelivr.net/npm/remixicon@2.2.0/fonts/remixicon.css" rel="stylesheet">
  <!-- 动画库 -->
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fushaolei/cdn-white@1.0/css/animate.css"/>
  
  <!-- css文件 -->
  
<link rel="stylesheet" href="/css/white.css">

  <!-- 代码高亮 -->
  
    
      
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.1.1/styles/github.css">

    
  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>

<!--动态线条背景-->
<script type="text/javascript"
color="200,200,200" opacity='0.8' zIndex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
</script>


<div class="menu-outer">
    <div class="menu-inner">
      <div class="menu-site-name  animate__animated  animate__fadeInUp">
        <a href="/">
          Fan&#39;s Notebook.
        </a>
        
      </div>
      <div class="menu-group">
        <ul class="menu-ul">
        
          <a href="/" class="nav-link">
            <li class="menu-li  animate__animated  animate__fadeInUp">
              HOME
            </li>
          </a>
        
          <a href="/archives" class="nav-link">
            <li class="menu-li  animate__animated  animate__fadeInUp">
              BLOG
            </li>
          </a>
        
        
          <li class="menu-li animate__animated  animate__fadeInUp" id="sort">
             CLASS
             <div class="categories-outer " id="sort-div">
               <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/DL-IC/">DL_IC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ROS/">ROS</a></li></ul>
             </div>
          </li>
        
        
          <li class="menu-li animate__animated  animate__fadeInUp" id="mobile-menu">
            <i class="ri-menu-line"></i>
          </li>
        
        </ul>

      </div>

    </div>
</div>
<div id="mobile-main" class="animate__animated  animate__fadeIn">
  <div class="mobile-menu-inner">
    <div class="mobile-menu-site-name animate__animated  animate__fadeInUp">
      <a href="/">
        Fan&#39;s Notebook.
      </a>
    </div>
    <div class="mobile-menu-group" id="mobile-close">
      <i class="ri-close-line"></i>
    </div>

  </div>

  <div class="mobile-menu-div">
  
    <a href="/" class="mobile-nav-link">
      <div class="mobile-menu-child animate__animated  animate__fadeInUp">
        <span>HOME</span>
      </div>
    </a>
  
    <a href="/archives" class="mobile-nav-link">
      <div class="mobile-menu-child animate__animated  animate__fadeInUp">
        <span>BLOG</span>
      </div>
    </a>
  
  
  </div>


</div>

<div class="body-outer">
  <div class="body-inner">
    
<article class="post-inner">
  <div class="post-content-outer">
    <div class="post-intro">
      <div class="post-title animate__animated  animate__fadeInUp">迁移学习猫狗图像分类</div>
      <div class="meta-intro animate__animated  animate__fadeInUp">Aug 19 2022</div>
      
    </div>
    <div class="post-content-inner">
      <div class="post-content-inner-space">

      </div>
      <div class="post-content-main animate__animated  animate__fadeInUp">
        <!-- top型目录 -->
        
        <pre><code class="python">from glob import glob
import os
import numpy as np
import matplotlib.pyplot as plt
import shutil
from torchvision import transforms
from torchvision import models
import torch
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import lr_scheduler
from torch import optim
from torchvision.datasets import ImageFolder
from torchvision.utils import make_grid
from torch.utils.data import Dataset,DataLoader
import time
%matplotlib inline
</code></pre>
<h2 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h2><pre><code class="python">!pip install kaggle
import json
token = &#123;&quot;username&quot;:&quot;wufankaggle&quot;,&quot;key&quot;:&quot;bda8c549328cf6dc227258aee7b72f78&quot;&#125;
with open(&#39;/content/kaggle.json&#39;, &#39;w&#39;) as file:
  json.dump(token, file)
!mkdir -p ~/.kaggle
!cp /content/kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle config set -n path -v /content
!kaggle competitions download -c dogs-vs-cats
!unzip /content/competitions/dogs-vs-cats/dogs-vs-cats.zip
!unzip test1.zip
!unzip train.zip
path = &#39;/content/train/&#39;
files = glob(os.path.join(path,&#39;*.jpg&#39;)) # os.path.join用于路径拼接
print(f&#39;Total no of images &#123;len(files)&#125;&#39;)
no_of_images = len(files)
# 创建混合索引
shuffle = np.random.permutation(no_of_images)
# 创建验证代码，验证集和测试集的区别在于，验证集是为了便于调参
# 创建validation目录和对应类别文件夹
for t in [&#39;train&#39;,&#39;valid&#39;]:
    os.mkdir(os.path.join(path,t))
    for folder in [&#39;dog/&#39;,&#39;cat/&#39;]:
        os.mkdir(os.path.join(path,t,folder))
# 将一小部分图片(随机挑选)复制到验证集文件夹
for i in shuffle[:2000]:
    folder = files[i].split(&#39;/&#39;)[-1].split(&#39;.&#39;)[0]
    image = files[i].split(&#39;/&#39;)[-1]
    os.rename(files[i],os.path.join(path,&#39;valid&#39;,folder,image))
# 将剩余图片复制到训练集文件夹
for i in shuffle[2000:]:
    folder = files[i].split(&#39;/&#39;)[-1].split(&#39;.&#39;)[0]
    image = files[i].split(&#39;/&#39;)[-1]
    os.rename(files[i],os.path.join(path,&#39;train&#39;,folder,image)) # 修改目录名
simple_transform = transforms.Compose([transforms.Resize((224,224))
                                       ,transforms.ToTensor()
                                       ,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                                      ])
train = ImageFolder(&#39;/content/train/train/&#39;,simple_transform)
valid = ImageFolder(&#39;/content/train/valid/&#39;,simple_transform)
</code></pre>
<pre><code class="python">train_data_loader = torch.utils.data.DataLoader(train,batch_size=64,shuffle=True,pin_memory=True,num_workers=3)
valid_data_loader = torch.utils.data.DataLoader(valid,batch_size=64,shuffle=True,pin_memory=True,num_workers=3)
</code></pre>
<h2 id="创建VGG16模型"><a href="#创建VGG16模型" class="headerlink" title="创建VGG16模型"></a>创建VGG16模型</h2><pre><code class="python"># 下载训练好的模型
vgg = models.vgg16(pretrained=True) # 加载调整好的权重
vgg = vgg.cuda()
</code></pre>
<p>eatures&#x3D;25088, out_features&#x3D;4096, bias&#x3D;True)<br>        (1): ReLU(inplace&#x3D;True)<br>        (2): Dropout(p&#x3D;0.5, inplace&#x3D;False)<br>        (3): Linear(in_features&#x3D;4096, out_features&#x3D;4096, bias&#x3D;True)<br>        (4): ReLU(inplace&#x3D;True)<br>        (5): Dropout(p&#x3D;0.5, inplace&#x3D;False)<br>        (6): Linear(in_features&#x3D;4096, out_features&#x3D;1000, bias&#x3D;True)<br>      )<br>    )</p>
<h2 id="微调VGG模型"><a href="#微调VGG模型" class="headerlink" title="微调VGG模型"></a>微调VGG模型</h2><pre><code class="python"># 将第6层的输出特征改为2个
vgg.classifier[6].out_features = 2
# 阻止优化器更新权重
for param in vgg.features.parameters(): param.requires_grad = False
</code></pre>
<pre><code class="python"># 只需要训练分类器参数
optimizer = optim.SGD(vgg.classifier.parameters(),lr=0.0001,momentum=0.5)
</code></pre>
<pre><code class="python">def fit(epoch,model,data_loader,phase=&#39;training&#39;,volatile=False):
    if phase == &#39;training&#39;:
        model.train()
    if phase == &#39;validation&#39;:
        model.eval()
        volatile=True
    running_loss = 0.0
    running_correct = 0
    for batch_idx , (data,target) in tqdm(enumerate(data_loader)):
        data,target = data.cuda(),target.cuda()
        data , target = Variable(data,volatile),Variable(target)
        if phase == &#39;training&#39;:
            optimizer.zero_grad()
        output = model(data)
        loss = F.cross_entropy(output,target)
        
        running_loss += F.cross_entropy(output,target,size_average=False).item()
        preds = output.data.max(dim=1,keepdim=True)[1]
        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()
        if phase == &#39;training&#39;:
            loss.backward()
            optimizer.step()
    
    loss = running_loss/len(data_loader.dataset)
    accuracy = 100. * running_correct/len(data_loader.dataset)
    
    print(f&#39;&#123;phase&#125; loss is &#123;loss:&#123;5&#125;.&#123;2&#125;&#125; and &#123;phase&#125; accuracy is &#123;running_correct&#125;/&#123;len(data_loader.dataset)&#125;&#123;accuracy:&#123;10&#125;.&#123;4&#125;&#125;&#39;)
    return loss,accuracy
</code></pre>
<pre><code class="python">from tqdm import tqdm
train_losses , train_accuracy = [],[]
val_losses , val_accuracy = [],[]
for epoch in range(1,10):
    epoch_loss, epoch_accuracy = fit(epoch,vgg,train_data_loader,phase=&#39;training&#39;)
    val_epoch_loss , val_epoch_accuracy = fit(epoch,vgg,valid_data_loader,phase=&#39;validation&#39;)
    train_losses.append(epoch_loss)
    train_accuracy.append(epoch_accuracy)
    val_losses.append(val_epoch_loss)
    val_accuracy.append(val_epoch_accuracy)
</code></pre>
<h2 id="调整dropout值"><a href="#调整dropout值" class="headerlink" title="调整dropout值"></a>调整dropout值</h2><pre><code class="python"># 使用不同dropout值改进模型的泛化能力
for layer in vgg.classifier.children():
    if(type(layer) == nn.Dropout):
        layer.p = 0.2
</code></pre>
<pre><code class="python">train_losses , train_accuracy = [],[]
val_losses , val_accuracy = [],[]
for epoch in range(1,3):
    epoch_loss, epoch_accuracy = fit(epoch,vgg,train_data_loader,phase=&#39;training&#39;)
    val_epoch_loss , val_epoch_accuracy = fit(epoch,vgg,valid_data_loader,phase=&#39;validation&#39;)
    train_losses.append(epoch_loss)
    train_accuracy.append(epoch_accuracy)
    val_losses.append(val_epoch_loss)
    val_accuracy.append(val_epoch_accuracy)
</code></pre>
<h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><pre><code class="python">train_transform = transforms.Compose([transforms.Resize((224,224))
                                       ,transforms.RandomHorizontalFlip() # 随机水平翻转图片
                                       ,transforms.RandomRotation(0.2) # 随机小角度旋转图像
                                       ,transforms.ToTensor()
                                       ,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                                      ])
train = ImageFolder(&#39;/content/train/train/&#39;,train_transform)
valid = ImageFolder(&#39;/content/train/valid/&#39;,simple_transform)
</code></pre>
<pre><code class="python">train_data_loader = DataLoader(train,batch_size=32,num_workers=3,shuffle=True)
valid_data_loader = DataLoader(valid,batch_size=32,num_workers=3,shuffle=True)
</code></pre>
<pre><code class="python">train_losses , train_accuracy = [],[]
val_losses , val_accuracy = [],[]
for epoch in range(1,3):
    epoch_loss, epoch_accuracy = fit(epoch,vgg,train_data_loader,phase=&#39;training&#39;)
    val_epoch_loss , val_epoch_accuracy = fit(epoch,vgg,valid_data_loader,phase=&#39;validation&#39;)
    train_losses.append(epoch_loss)
    train_accuracy.append(epoch_accuracy)
    val_losses.append(val_epoch_loss)
    val_accuracy.append(val_epoch_accuracy)
</code></pre>
<h2 id="计算预卷积特征"><a href="#计算预卷积特征" class="headerlink" title="计算预卷积特征"></a>计算预卷积特征</h2><pre><code class="python">vgg = models.vgg16(pretrained=True)
vgg = vgg.cuda()
</code></pre>
<pre><code>/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter &#39;pretrained&#39; is deprecated since 0.13 and will be removed in 0.15, please use &#39;weights&#39; instead.
  f&quot;The parameter &#39;&#123;pretrained_param&#125;&#39; is deprecated since 0.13 and will be removed in 0.15, &quot;
/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for &#39;weights&#39; are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
</code></pre>
<pre><code class="python">features = vgg.features
</code></pre>
<pre><code class="python">for param in features.parameters(): param.requires_grad = False
</code></pre>
<pre><code class="python">train_data_loader = torch.utils.data.DataLoader(train,batch_size=32,num_workers=3,shuffle=False)
valid_data_loader = torch.utils.data.DataLoader(valid,batch_size=32,num_workers=3,shuffle=False)
</code></pre>
<pre><code class="python"># preconvfeat方法接受数据集和vgg模型，返回卷积特征和对应标签
def preconvfeat(dataset,model):
    conv_features = []
    labels_list = []
    for data in tqdm(dataset):
        inputs,labels = data
        inputs , labels = inputs.cuda(),labels.cuda()       
        inputs , labels = Variable(inputs),Variable(labels)
        output = model(inputs)
        conv_features.extend(output.data.cpu().numpy())
        labels_list.extend(labels.data.cpu().numpy())
    conv_features = np.concatenate([[feat] for feat in conv_features])
    
    return (conv_features,labels_list)
</code></pre>
<pre><code class="python">class My_dataset(Dataset):
    def __init__(self,feat,labels):
        self.conv_feat = feat
        self.labels = labels
    
    def __len__(self):
        return len(self.conv_feat)
    
    def __getitem__(self,idx):
        return self.conv_feat[idx],self.labels[idx]
</code></pre>
<pre><code class="python">train_feat_dataset = My_dataset(conv_feat_train,labels_train)
val_feat_dataset = My_dataset(conv_feat_val,labels_val)
</code></pre>
<pre><code class="python">train_feat_loader = DataLoader(train_feat_dataset,batch_size=64,shuffle=True)
val_feat_loader = DataLoader(val_feat_dataset,batch_size=64,shuffle=True)
</code></pre>
<pre><code class="python">def data_gen(conv_feat,labels,batch_size=64,shuffle=True):
    labels = np.array(labels)
    if shuffle:
        index = np.random.permutation(len(conv_feat))
        conv_feat = conv_feat[index]
        labels = labels[index]
    for idx in range(0,len(conv_feat),batch_size):
        yield(conv_feat[idx:idx+batch_size],labels[idx:idx+batch_size])
</code></pre>
<pre><code class="python">train_batches = data_gen(conv_feat_train,labels_train)
val_batches = data_gen(conv_feat_val,labels_val)
</code></pre>
<pre><code class="python">optimizer = optim.SGD(vgg.classifier.parameters(),lr=0.0001,momentum=0.5)
</code></pre>
<pre><code class="python">def fit_numpy(epoch,model,data_loader,phase=&#39;training&#39;,volatile=False):
    if phase == &#39;training&#39;:
        model.train()
    if phase == &#39;validation&#39;:
        model.eval()
        volatile=True
    running_loss = 0.0
    running_correct = 0
    for batch_idx , (data,target) in enumerate(data_loader):
        data,target = data.cuda(),target.cuda()
        data , target = Variable(data,volatile),Variable(target)
        if phase == &#39;training&#39;:
            optimizer.zero_grad()
        data = data.view(data.size(0), -1)
        output = model(data)
        loss = F.cross_entropy(output,target)
        
        running_loss += F.cross_entropy(output,target,size_average=False).item()
        preds = output.data.max(dim=1,keepdim=True)[1]
        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()
        if phase == &#39;training&#39;:
            loss.backward()
            optimizer.step()
    
    loss = running_loss/len(data_loader.dataset)
    accuracy = 100. * running_correct/len(data_loader.dataset)
    
    print(f&#39;&#123;phase&#125; loss is &#123;loss:&#123;5&#125;.&#123;2&#125;&#125; and &#123;phase&#125; accuracy is &#123;running_correct&#125;/&#123;len(data_loader.dataset)&#125;&#123;accuracy:&#123;10&#125;.&#123;4&#125;&#125;&#39;)
    return loss,accuracy
</code></pre>
<pre><code class="python">%%time
train_losses , train_accuracy = [],[]
val_losses , val_accuracy = [],[]
for epoch in range(1,20):
    epoch_loss, epoch_accuracy = fit_numpy(epoch,vgg.classifier,train_feat_loader,phase=&#39;training&#39;)
    val_epoch_loss , val_epoch_accuracy = fit_numpy(epoch,vgg.classifier,val_feat_loader,phase=&#39;validation&#39;)
    train_losses.append(epoch_loss)
    train_accuracy.append(epoch_accuracy)
    val_losses.append(val_epoch_loss)
    val_accuracy.append(val_epoch_accuracy)
</code></pre>
<pre><code>/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction=&#39;sum&#39; instead.
  warnings.warn(warning.format(ret))


training loss is   5.9 and training accuracy is 6907/23000     30.03
validation loss is   1.0 and validation accuracy is 1622/2000      81.1
training loss is  0.47 and training accuracy is 20597/23000     89.55
validation loss is  0.22 and validation accuracy is 1900/2000      95.0
training loss is  0.19 and training accuracy is 21782/23000      94.7
validation loss is  0.14 and validation accuracy is 1922/2000      96.1
training loss is  0.14 and training accuracy is 22085/23000     96.02
validation loss is  0.11 and validation accuracy is 1935/2000     96.75
training loss is  0.11 and training accuracy is 22199/23000     96.52
validation loss is 0.098 and validation accuracy is 1939/2000     96.95
training loss is 0.099 and training accuracy is 22307/23000     96.99
validation loss is 0.089 and validation accuracy is 1946/2000      97.3
training loss is 0.089 and training accuracy is 22366/23000     97.24
validation loss is 0.084 and validation accuracy is 1948/2000      97.4
training loss is 0.086 and training accuracy is 22366/23000     97.24
validation loss is 0.079 and validation accuracy is 1952/2000      97.6
training loss is 0.078 and training accuracy is 22418/23000     97.47
validation loss is 0.076 and validation accuracy is 1953/2000     97.65
training loss is 0.075 and training accuracy is 22429/23000     97.52
validation loss is 0.073 and validation accuracy is 1954/2000      97.7
training loss is  0.07 and training accuracy is 22476/23000     97.72
validation loss is 0.071 and validation accuracy is 1955/2000     97.75
training loss is 0.069 and training accuracy is 22486/23000     97.77
validation loss is 0.069 and validation accuracy is 1955/2000     97.75
training loss is 0.069 and training accuracy is 22478/23000     97.73
validation loss is 0.068 and validation accuracy is 1955/2000     97.75
training loss is 0.064 and training accuracy is 22509/23000     97.87
validation loss is 0.066 and validation accuracy is 1956/2000      97.8
training loss is 0.063 and training accuracy is 22518/23000      97.9
validation loss is 0.065 and validation accuracy is 1959/2000     97.95
training loss is 0.058 and training accuracy is 22550/23000     98.04
validation loss is 0.064 and validation accuracy is 1959/2000     97.95
training loss is 0.058 and training accuracy is 22556/23000     98.07
validation loss is 0.063 and validation accuracy is 1959/2000     97.95
training loss is 0.057 and training accuracy is 22565/23000     98.11
validation loss is 0.062 and validation accuracy is 1959/2000     97.95
training loss is 0.058 and training accuracy is 22550/23000     98.04
validation loss is 0.061 and validation accuracy is 1961/2000     98.05
CPU times: user 4min 4s, sys: 1.22 s, total: 4min 6s
Wall time: 4min 6s
</code></pre>

        <!-- 分类文章 -->
        
          <div class="post-categoris-bottom">
            <div class="post-categoris-name">DL_IC</div>
            <ul>
            
            
              
            
            
            
              
            
            
            
              
            
            
            
              
            
            
            
              
            
            
            
              
            
            
            
              
                <li class="base">
                  <a  href="/2022/08/15/1.2.%E5%9F%BA%E4%BA%8EMac%E7%9A%84mps%E5%8A%A0%E9%80%9F%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" class="post-categoris-bottom-link">
                  基于mps加速的猫狗图像分类
                </a>
                </li>
              
              
            
            
            
              
                <li class="base">
                  <a  href="/2022/08/16/1.1.%E5%9F%BA%E4%BA%8Ecuda%E7%9A%84%E7%8C%AB%E7%8B%97%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" class="post-categoris-bottom-link">
                  基于cuda加速的猫狗图像分类
                </a>
                </li>
              
              
            
            
            
              
                <li class="base">
                  <a  href="/2022/08/17/2.%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/" class="post-categoris-bottom-link">
                  手写数字图像分类
                </a>
                </li>
              
              
            
            
            
              
                <li class="base">
                  <a  href="/2022/08/18/3.%E6%9E%84%E5%BB%BACNN%E5%AF%B9%E7%8C%AB%E7%8B%97%E5%88%86%E7%B1%BB/" class="post-categoris-bottom-link">
                  CNN猫狗图像分类
                </a>
                </li>
              
              
            
            
            
              
                <li class="me base">
                  <a  href="/2022/08/19/4.%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8C%AB%E7%8B%97%E5%88%86%E7%B1%BB/" class="post-categoris-bottom-link">
                  迁移学习猫狗图像分类
                </a>
                </li>
              
              
            
            
            
              
                <li class="base">
                  <a  href="/2022/09/06/8.%E5%9F%BA%E4%BA%8EResNeXt50_32X4D%E7%9A%84%E6%A0%91%E5%8F%B6%E5%88%86%E7%B1%BB/" class="post-categoris-bottom-link">
                  基于ResNeXt50_32X4D的树叶分类
                </a>
                </li>
              
              
            
            
            </ul>

          </div>

        
      </div>
      <div class="post-content-inner-space">
        
          <div class="space-toc-main animate__animated  animate__fadeInUp">
            <ol class="space-toc"><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="space-toc-text">加载数据集</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#%E5%88%9B%E5%BB%BAVGG16%E6%A8%A1%E5%9E%8B"><span class="space-toc-text">创建VGG16模型</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#%E5%BE%AE%E8%B0%83VGG%E6%A8%A1%E5%9E%8B"><span class="space-toc-text">微调VGG模型</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#%E8%B0%83%E6%95%B4dropout%E5%80%BC"><span class="space-toc-text">调整dropout值</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="space-toc-text">数据增强</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#%E8%AE%A1%E7%AE%97%E9%A2%84%E5%8D%B7%E7%A7%AF%E7%89%B9%E5%BE%81"><span class="space-toc-text">计算预卷积特征</span></a></li></ol>
           </div>
        
      </div>
   </div>
    <!-- 评论 -->
    
  </div>
</article>
  </div>
</div>



<!-- 如果是home模式的话，不在首页就显示footer，如果不是home模式的话 所有都显示footer -->

  <div class="footer-outer animate__animated  animate__fadeInUp">
    <div class="footer-inner">
    <div class="footer-text">
    <p>Power by Guo_Yifan</p>

    </div>
    <div class="footer-contact">
    <ul class="footer-ul">
        
        <li class="footer-li">
            <a href="https://github.com" target="_blank">
                <i class="ri-github-line"></i>
            </a>
        </li>
        
        <li class="footer-li">
            <a href="mailto:guoyf@mail.nwpu.edu.cn" target="_blank">
                <i class="ri-mail-line"></i>
            </a>
        </li>
        
    </ul>
    </div>
    </div>
</div>






<script src="/js/white.js"></script>



    
      
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.1/build/highlight.min.js"></script>

      <script>hljs.initHighlightingOnLoad();</script>
    

</body>
</html>
